- RDD 생성시 파티션 개수
    - ex) `sc.parallelize(Array(1, 2, 3, 1, 2, 3, 4), 3)` 
    - 두번쨰 파라미터에 파티션 개수 지정 가능
    - 만약 지정하지 않을 경우 설정값 `spark.default.parallelism` 사용
    - `spark.default.parallelism`도 없을 경우 total core를 고려함
    - local 실행시엔 `local[core수]` 에서 명시한 core수가 total core
    - 배포시엔 max(2, total core수) 로 보임. (CoarseGrainedSchedulerBackend 참고)
  
- 구조적 API 리파티셔닝
  - `df.repartition(5, col("DEST_COUNTRY_NAME))` 과 같이 특정 컬럼 기준으로 파티셔닝 가능.
  - 특정 컬럼 기준으로 자주 필터링 한다면 자주 필터링 되는 컬럼을 기준으로 파티션 재분배하는게 좋다고 함.
  