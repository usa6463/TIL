# 저장소와 검색

- 특정 작업부하(workload) 유형에서 좋은 성능을 내게끔 저장소 엔진을 조정하려면 저장소 엔진이 내부에서 수행된느 작업에 대해 대략적인 개념을 이해할 필요가 있다.
- 트랜잭션 작업부하게 맞춰 최적화된 저장소 엔진과, 분석을 위해 최적화된 엔진 간에는 큰 차이가 있음
- 이번 장에서는 관계형 DB, NoSQL DB에서 사용하는 저장소 엔진에 대해 설명
- 그리고 log structured, page-oriented 계열 저장소 엔진 검토

## 데이터베이스를 강력하게 만드는 데이터 구조
- 많은 데이터베이스는 내부적으로 추가 전용(append-only) 데이터 파일인 로그를 사용
    - 이 책에서 로그는 연속된 추가 전용 레코드를 의미
- 키-값 저장소에서 색인이 없으면 매번 키를 찾을 때 마다 전체 데이터베이스 파일을 처음부터 끝까지 스캔해야 한다
    - O(n) 검색 비용
- 색인
    - 일반적인 개념은 어떤 부가적인 메타데이터를 유지하는 것. 
    - 어떤 종류의 색인이라도 쓰기 속도를 느리게 만든다 
        - 이는 데이터 쓸 때마다 매번 색인도 갱신해야 하기 때문
        - 저장소 시스템에서의 트레이드 오프
            - 색인을 잘 선택하면 읽기 질의 속도가 올라가지만 모든 색인은 쓰기 속도를 떨어뜨린다
        - 개발자나 데이터베이스 관리자가 수동으로 적절 색인 선택해야 함.
    
- 해시 색인
    - 키-값 데이터의 색인은 보통 해시맵으로 구현한다. 
    - 예제처럼 단순히 파일에 추가하는 방식으로 데이터 저장소를 구성한다고 가정할 때 간단하게 가능한 색인 전략
        - 키를 데이터 파일의 바이트 오프셋에 매핑해 인메모리 해시 맵을 유지
        - 파일에 새로운 키-값 쌍 추가할 때 마다 방금 기록한 데이터의 오프셋 반영을 위해 해시맵 갱신 필요
        - 값을 조회 하려면 해시맵을 사용해 데이터 파일에서 오프셋을 찾아 해당 위치를 구하고 값을 읽는다.
        - 비트캐스크(리악의 기본 저장소 엔진)가 근본적으로 사용하는 방식
    - 각 키의 값이 자주 갱신되는 상황에 매우 적합
        - ex) 키는 동영상 URL, 값은 비디오가 재생된 횟수
        - 키당 쓰기 수가 많지만 메모리에 모든 키를 보관 가능
    - 디스크 공간 부족 대처
        - 항상 추가만 하면 결국 디스크 공간 부족해짐
        - 특정 크기의 세그먼트로 로그를 나누는 방식이 좋은 해결책
        - 특정 크기에 도달하면 세그먼트 파일을 닫고 새로운 세그먼트 파일에 쓰기 수행
        - 세그먼트 파일들에 대해 컴팩션 수행
            - 컴팩션은 로그에서 중복된 키를 버리고 각 키의 최신 갱신 값만 유지 하는 것
        - 컴팩션 수행 시 동시에 여러 세그먼트 병합 가능
        - 세그먼트가 쓰여진 후 절대 변경 불가능하므로 병합할 세그먼트는 새로운 파일로 생성
            - 컴팩션 수행 중 이전 세그먼트 파일 사용해 읽기와 쓰기 요청 처리 정상적으로 수행 가능
            - 병합 종료 후 읽기 요청은 이전 세그먼트 대신 새로 병합한 세그먼트 사용하게 전환 
            - 전환 후 이전 세그먼트 파일은 삭제
        - 각 세그먼트는 키를 파일 오프셋에 매핑한 자체 인메모리 해시 테이블을 가진다. 
    - 실제 구현에서 중요한 문제
        - 파일 형식
            - CSV 보단 바이트 단위의 문자열 길이를 부호화한 다음 원시 문자열을 부호화 하는 바이너리 형식 사용하는 편이 더 빠르고 간단
        - 레코드 삭제
            - 키와 관련된 데이터 삭제 시 데이터 파일에 특수한 삭제 레코드(툼스톤) 추가 필요
        - 고장(crash) 복구
            - DB가 재시작되면 인메모리 해시맵이 소멸됨. 각 세그먼트 해시맵의 스냅숏을 디스크에 저장해 복구 속도 높인다.
        - 부분적 레코드 쓰기
            - DB는 로그에 레코드를 추가하는 도중에도 죽을 수 있다. 파일이 체크섬을 가지고 있으면 로그의 손상된 부분을 탐지해 무시할 수 있다.
        - 동시성 제어
            - 쓰기를 엄격하게 순차적으로 로그에 추가 시 일반적인 구현바업은 하나의 쓰기 스레드만 사용
            - 데이터 파일 세그먼트는 추가 전용이거나 불변이므로 다중 스레드로 동시에 읽기할 수 있다. 
    - 추가 전용(append-only) 설계의 장점
        - 추가와 세그먼트 병합은 순차적인 쓰기 작업이기 때문에 보통 무작위 쓰기보다 훨씬 빠르다. 
        - 세그먼트 파일이 추가 전용이나 불변이면 동시성과 고장 복구과 훨씬 간단. 
        - 오래된 세그먼트 병합은 조각화 되면 데이터 파일 문제 회피 가능
    - 해시 테이블 색인 제한 사항
        - 키가 너무 많으면 메모리 저장이 어려워진다.
            - 디스크에도 해시 맵 유지 가능하지만 좋은 성능 기대 어려움
            - 디스크에선 무작위 접근 I/O가 많이 필요하고 디스크 가득 찼을 때 확장 비용이 비싸며 해시 충돌 해소를 위한 성가신 로직 필요
        - 범위 질의(range query)에 효율적이지 않다. 
    
- SS테이블과 LSM 트리
    - SS테이블
        - Sorted String Table
        - 조건 
            - 키로 정렬된 테이블
            - 각 키는 각 병합된 세그먼트 파일 내에 한 번만 나타나야 한다. (컴팩션 과정은 이를 이미 보장)
        - 해시 색인 가진 로그 세그먼트 대비 장점
            - 세그먼트 병합은 파일이 사용 가능한 메모리보다 크더라도 간단하고 효율적
                - mergesort와 비슷한 방식
                - 먼저 입력 파일을 함께 읽고 각 파일의 첫 번째 키를 본다. 
                - 그리고 가장 낮은 키를 출력 파일로 복사한 뒤 이 과정을 반복
                - 새로운 세그먼트 파일도 키로 정렬되어 있음.
                - 만약 여러 세그먼트에 동일한 키가 있으면? 가장 최근 세그먼트의 값은 유지하고 오래된 세그먼트의 값은 버린다
                - SS테이블이 아니고, 컴팩션 대상 파일 크기가 메모리보다 클 경우 컴팩션 속도가 매우 느릴 것 같다(컨텍스트 스위칭)
            - 파일에서 특정 키를 찾기 위해 더는 메모리에 모든 키의 색인을 유지할 필요가 없다.
                - 전체 키에 대한 색인 대신 sparse index를 사용한다 
                - 예를들어 handiwork라는 키를 찾고자 할 때 sparse index에 handbag과 handsome이 있다면 두 키의 오프셋 사이를 스캔하면 된다.
                - 수 킬로 바이트 정도는 매우 빠르게 스캔할 수 있으므로 세그먼트 파일 내 수 킬로바이트당 키 하나로 충분
            - 디스크 공간 절약 및 I/O 대역폭 사용 줄임
                - 읽기 요청은 범위내에서 여러 키-값 쌍을 스캔해야 하므로 해당 레코드들을 블록으로 그룹화 하고 디스크에 쓰기전 압축한다.
                - sparse index 각 항목은 압축된 블록의 시작을 가리키게 된다. 
    - SS 테이블 생성과 유지
        - 유입되는 쓰기는 임의 순서일텐데 어떻게 SS 테이블 형태를 유지하나?(키로 정렬)
            - SS테이블 동작 순서
                - 쓰기가 들어오면 인메모리 균형트리(memtable이라고도 함)에 추가
                - 멤테이블이 보통 수 메가바이트 정도의 임곗값보다 커지면 SS 테이블 파일로 디스크에 기록(DB의 가장 최신 세그먼트가 됨)
                - SS 테이블을 디스크에 기록하는 동안 쓰기는 새로운 멤테이블 인스턴스에 기록
                - 읽기 요청은 멤테이블에서 키를 찾고, 없으면 그다음 디스크상의 최신 세그먼트에서 찾음. 없을 때 마다 두번째, 세번째,... 세그먼트 파일 조회
                - 가끔 세그먼트 파일에 대한 병합과 컴팩션 수행. 이 과정은 백그라운드에서 실행 
            - 멤테이블
                - 임의 순서로 키 삽입 하고 정렬된 순서로 해당 키를 다시 읽을 수 있음.                
                - 종류
                  - 레드 블랙 트리, AVL 트리
            - DB 고장 대처
                - DB 고장 시 멤테이블(메모리에 존재)에 있는 최신 쓰기는 손실됨.
                - 이 문제 피하기 위해 매번 쓰기를 즉시 추가할 수 있게 분리된 로그를 디스크상에 유지
                - 이 로그는 손상 후 멤테이블 복원할때만 사용하므로 순서 정렬되지 않아도 괜찮음.
                - 멤테이블을 SS 테이블로 기록하면 해당 로그는 버릴 수 있다.
    - SS 테이블에서 LSM 트리 만들기
        - LSM 트리: Log-Structured Merge-Tree (로그 구조화 병합 트리)
        - LSM 저장소 엔진: 정렬된 파일 병합과 컴팩션 원리를 기반으로 하는 저장소 엔진
        - LevelDB, RocksDB에서 사용, 카산드라와 HBase도 유사한 저장소 엔진 사용
        - 루씬은 ES나 솔라에서 사용하는 전문(full-text) 검색 색인 엔진이고, 용어 사전을 저장하기 위해 유사한 방법 사용
        - 이 부분에서 말하고자하는건 SS테이블을 통해 LSM 트리가 구성될 수 있다인듯
        
    - 성능 최적화
        - 블룸 필터(Bloom filter)
            - LSM 트리 알고리즘은 DB에 존재하지 않는 키 찾을 경우 느릴 수 있다.
            - 존재하지 않음을 확인하려면 가장 오래된 세그먼트까지 거슬러가야함
            - 블룸필터는 집합 내용을 근사한(approximating) 메모리 효율적 데이터 구조
            - 블룸 필터는 키가 데이터베이스에 존재하지 않음을 알려줘서 불필요한 디스크 읽기 절약 가능
        - SS 테이블 압축 및 병합의 순서와 시기 결정 전략
            - size-tiered(사이즈 계층)
                - HBase, 카산드라 지원
                - 상대적으로 좀 더 새롭고 작은 SS테이블을 상대적으로 오래됐고 큰 SS테이블에 연이어 병합
            - leveled compaction
                - 키 범위를 더 작은 SS테이블로 나누고 오래된 데이터는 개별 "레벨"로 이동
                - 컴팩션을 점진적으로 진행해 디스크 공간을 덜 사용
    
- B트리
    - 가장 널리 사용되는 색인 구조
    - SS테이블과 같이 키로 정렬된 키-값 쌍을 유지하기 때문에 키-값 검색과 범위 질의에 효율적
    - 전통적으로 4KB 크기(때로는 더 큰)의 고정 크기 블록이나 페이지로 나누고 한 번에 하나의 페이지에 읽기 또는 쓰기
    - 각 페이지는 주소나 위치를 이용해 식별
    - 하나의 페이지가 다른 페이지를 참조 가능
    - 한 페이지는 B트리의 root로 지정되고, 색인에서 키를 찾으려면 루트에서 시작한다. 
    - 최종적으로는 개별키(leaf page)를 포함하는 페이지 도달. 이 페이지는 각 키의 값을 포함하거나 값을 찾을 수 있는 페이지의 참조를 포함
    - 분기 계수(branching factor): 한 페이지에서 하위 페이지 참조하는 수
    - 키의 값을 갱신하려면 키를 포함하고 있는 리프 페이지를 검색하고 페이지의 값을 바꾼 후 디스크에 다시 기록
    - 새로운 키 추가는 새로운 키를 포함하는 범위의 페이지를 찾아 해당 페이지에 키와 값을 추가한다.
        - 새로운 키 수용한 페이지에 여유공간이 없다면 페이지 하나를 반쯤 채워지 페이지 둘로 나누고 상위 페이지가 새로운 키 범위의 하위 부분들을 알 수 있게 갱신
    - n개의 키를 가진 B트리는 깊이가 항상 O(log n)
    - 분기 계수 500, 4KB 페이지의 4단계(깊이) 트리는 256TB 까지 저장 가능

- 신뢰할 수 있는 B 트리 
     - B트리의 쓰기 동작 특징
        - 새로운 데이터를 디스크 상의 페이지에 덮어씀
        - LSM 트리 같은 로그 구조화 색인과 대조적. 로그 구조화 색인은 파일에 추가만 한다.
    - 다수의 페이지에 대한 덮어쓰기 필요
        - ex) 삽입 시 페이지가 꽉 차서 나눠야 하는 상황엔 분할된 두 페이지 기록, 두 하위 페이지의 참조를 갱신
        - 일부 페이지만 기록하고 DB가 고장나면 색인이 훼손된다.
            - 고아 페이지 발생 가능. 고아 페이지는 어떤 페이지와도 부모 관계가 없는 페이지
    - 고장 상황에서의 자동 복구
        - 디스크 상에 쓰기 전 로그(write-ahead log, WAL)(재실행 로그 redo log)라고 하는 데이터 구조를 추가
        - 트리 페이지에 변경된 내용 적용 전에 모든 B 트리의 변경 사항을 기록하는 추가 전용 파일
    - B 트리에 대한 동시성 제어
        - 다중 스레드가 동시에 B트리에 접근하는 경우
        - 스레드가 일관성이 깨진 상태의 트리에 접근할 수 있다.
        - 동시성 제어는 latch로 트리의 데이터 구조 보호

- B 트리 최적화 
    - 쓰기 시 복사 방식(copy-on-write scheme)
        - WAL 유지 대신 사용
        - 변경된 페이지는 다른 위치에 기록하고 트리에 상위 페이지의 새로운 버전을 만들어 새로운 위치를 가리키게 한다. 
    - 페이지에서 키를 축약
        - 키는 키 범위 사이의 경계 역할을 하는데 충분한 정보만 제공하면 됨.
        - 페이지 하나에 키를 더 많이 채우면 더 높은 분기계수를 얻고 트리 깊이 수준을 낮출 수 있다.
    - 정렬된 순서로 키 범위의 상당 부분 스캔 시
        - 리프 페이지를 디스크 상에 연속된 순서로 나타나게끔 트리 배치 시도
        - 트리에 포인터를 추가. 예를 들어 각 리프 페이지가 양쪽 형제 페이지에 대한 참조를 가지면 상위 페이지로 가지 않아도 순서대로 키 스캔 가능
    - 프랙탈 트리
        - B 트리 변형은 디스크 찾기를 줄이기 위해 로그 구조화 개념을 일부 빌림. 
    
- B 트리와 LSM 트리 비교
    - B 트리가 LSM 트리보다 일반적으로 구현 성숙도가 더 높지만 LSM 트리도 성능 특성 때문에 관심을 받고 있음
    - 경험적으로 LSM 트리는 쓰기에서 더 빠르고 B 트리는 읽기에서 더 빠르다고 여긴다
    - 비교가 유효하려면 실제 필요한 작업부하로 시스템을 테스트 해야함. 
    
- LSM 트리의 장점
    - B트리에 비해 쓰기 증폭(write amplification)이 낮다.
        - B 트리 색인
            - 모든 데이터 조각을 최소한 두 번 기록해야 한다. 
                - WAL 한 번과 트리 페이지에 한 번
            - 페이지 내 몇 바이트만 바뀌어도 한 번에 전체 페이지 기록해야 하는 오버헤드 존재 가능
        - 저장소 엔진이 디스크에 기록할수록 디스크 대역폭 내 처리할 수 있는 초당 쓰기는 점점 줄어듬
        - 쓰기가 많은 app 에서 성능 병목은 DB가 디스크에 쓰는 속도일 수 있다.
    - 쓰기 처리량을 높게 유지할 수 있다.
        - 쓰기 증폭이 낮고, 트리에서 여러 페이지를 덮어 쓰는게 아니라 순차적으로 컴팩션된 SS 테이블 파일을 쓰기 때문
        - HDD는 순차 쓰기가 임의 쓰기보다 훨씬 빠름
    - 압축률이 좋음
        - B 트리는 파편화로 인해 사용하지 않는 디스크 공간 일부가 남음
        - 페이지 나누거나 로우가 기존에 페이지에 맞지 않을 때 페이지 일부 공간은 사용하지 않게 됨.
        - LSM 트리는 주기적으로 파편화를 없애기 위해 SS 테이블을 다시 기록하므로 저장소 오버헤드가 더 낮다
    - 낮은 쓰기 증폭과 파편화 감소는 SSD의 경우 훨씬 유리
        - 데이터를 더 밀집해 포현하면 가능한 I/O 대역폭 내에서 더 많은 읽기와 쓰기 요청이 가능
    
- LSM 트리의 단점 
    - 컴팩션 과정이 읽기와 쓰기 성능에 영향
        - 컴팩션을 점진적으로 수행하고 동시 접근 영향 없게 수행하려 하지만 디스크가 가진 자원의 한계가 있음.
        - 디스크에서 비싼 컴팩션 연산이 끝날 때 까지 요청이 대기해야 하는 상황 발생 가능
    - 컴팩션의 높은 쓰기 처리량
        - 디스크의 쓰기 대역폭은 유한
        - DB가 점점 커질수록 컴팩션을 위해 더 많은 디스크 대역폭 필요
    - 컴팩션이 유입 쓰기 속도 따라가지 못하는 경우
        - 디스크 상에 병합되지 않은 세그먼트 수가 디스크 공간이 부족할 때 까지 증가
        - 더 많은 세그먼트 파일 확인해야 하므로 읽기 또한 느려짐
    - 같은 키의 다중 복사본 존재 가능
        - 각 키가 색인의 한곳에만 존재하는 B 트리는 강력한 트랜잭션 시맨틱을 제공한다. 
    
- 기타 색인 구조
    - 기본키(primary key)색인
        - 키-값 색인의 대표적인 예
        - DB에서 기본키로 로우/문서/정점을 참조할 수 있다.
        - 색인은 이런 참조를 찾을 때 사용
    - 보조 색인(secondary index)
        - 효율적으로 조인을 수행하는 데 결정적인 역할
        - 기본키 색인과의 차이점은 키가 고유하지 않다는 것. 
            - 해결 방법
                - 색인의 각 값에 일치하는 로우 식별자 목록 생성
                - 로우 식별자를 추가해 각 키를 고유하게 만드는 방법
        - 보조색인으로 B 트리와 로그 구조화 색인 둘 다 사용할 수 있다. 
    
- 색인 안에 값 저장하기 
    - 키는 질의가 검색하는 대상
    - 값은 질문의 실제 로우(문서, 정점)거나 다른 곳에 저장된 로우를 가리키는 참조
        - 후자의 로우가 저장된 곳은 힙 파일(heap file)이라 하고 특정 순서 없이 데이터 저장
    - 보조색인이 많을 경우 색인에서 값들을 저장하면 중복 데이터 발생 가능하지만 힙 파일 사용하면 중복 피할 수 있음
    - 힙 파일은 키를 변경하지 않고 값을 갱신 시 효율적
        - 새로운 값이 이전 값보다 많은 공간 필요하지 않으면 덮어쓸 수 있음
        - 더 많은 공간 필요하면, 충분한 공간이 있는 새로운 곳으로 위치 이동하고 모든 색인이 레코드의 새로운 힙 위치를 가리키게 갱신하거나 이전 힙 위치에 전방향 포인터 남겨야 함.
    - 색인 내 값 저장 방식
        - 클러스터드 색인
            - 색인 안에 색인된 로우를 저장
        - 커버링 색인
            - 클러스터드와 비클러스터드(색인 안에 데이터 참조만 저장) 사이의 절충안
            - 포괄열이 있는 색인(index with included column)이라 한다.
            - 색인 안에 테이블의 칼럼 일부를 저장. 
                - 일부 질의에 색인만 사용하여 응답 가능하고 이런 경우 색인이 질의를 커버했다고 함
        - 단점
            - 읽기 성능을 높일 수 있지만 추가적인 저장소가 필요하고 쓰기 과정에서 오버헤드 발생
            - 또 app 단에서 복제로 인한 불일치를 파악할 수 없어서 트랜잭션 보장을 위한 별도의 노력 필요
    
- 다중 칼럼 색인
    - 지금까지 설명한 색인은 하나의 키에만 대응. 테이블의 다중 컬럼에 동시에 질의해야하면 충분하지 않다.
    - 결합색인(concatenated index)
        - 하나의 칼럼에 다른 칼럼을 추가하는 방식
        - (성, 이름)을 키로 하는 구식 종이 전화번호부와 유사
    
    - 다차원 색인
        - 특히 지리 공간 데이터에 중요하게 사용
    
    - R트리
        - 전문 공간 색인(specialized spatial index)
    
- 전문 검색과 퍼지 색인
    - 지금까지 설명한 색인은 철자가 틀린 단어 같이 유사한 키에 대해서는 검색할 수 없다.
    - 애매모호한(fuzzy) 질의에는 다른 기술이 필요
    - 전문 검색 엔진
        - 특정 단어 검색 시 해당 단어의 동의어로 질의를 확장
        - 다양한 기능 제공
            - 단어의 문법적 활용 무시하고 동일한 문서에서 서로 인접해 나타난 단어를 검색
            - 언어학적으로 텍스트를 분석해 사용
        - 특정 편집거리 내 단어 검색
            - 편집거리: 편집거리 1은 한 글자가 추가되거나 삭제, 교체 됐음을 의미
    - 루씬에서 인메모리 색인은 여러 키 내 문자에 대한 유한 상태 오토마톤으로 트라이와 유사
    - 이 오토마톤은 레벤슈타인 오토마톤으로 변환 가능
    - 레벤슈타인 오토마톤은 특정 편집 거리 내에서 효율적인 단어 검색 제공
    
- 모든 것을 메모리에 보관
    - 디스크의 특징
        - 메인 메모리와 비교해 다루기 어려움
        - 좋은 성능을 원한다면 주의해서 데이터를 디스크에 배치 필요
        - 장점
            - 지속성
            - 메모리 보다 저렴
            - 디스크에 기록하면 파일은 쉽게 백업 가능하고 외부 유틸리를 이용해 검사와 분석 가능
        - 운영체제가 최근에 사용한 디스크 블록은 메모리에 캐시하기 때문에 충분한 메모리 가진 경우 디스크에서 읽을 필요가 없음
        - 오히려 인메모리 데이터 구조를 디스크에 기록하기 위한 형태로 부호화 하는 오버헤드 피할 수 있어 더 빠를 수 있다.
        
    - 인 메모리 데이터베이스
        - 램은 점점 저렴해졌고, 데이터셋 대부분이 그다지 크지 않기에 메모리에 전체를 보관하는 방식이 꽤 현실적이다
        - 일부 인메모리 DB는 장비 재시작시 데이터 손실을 허용하는 캐시 용도로 사용
        - 다른 인메모리 DB는 지속성을 목표
            - 특수 하드웨어 사용하거나
            - 디스크에 변경 사항의 로그를 기록하거나
            - 디스크에 주기적인 스냅숏 기록하거나
            - 다른 장비에 인메모리 상태 복제하거나
        - 디스크 기반 색인으로 구현하기 어려운 데이터 모델 제공
            - 우선순위 큐
            - 셋(set)
        - 안티 캐싱
            - 메모리가 충분하지 않을 때 가장 최근에 사용하지 않은 데이터를 메모리에서 디스크로 내보내고 나중에 다시 접근할 때 메모리에 적재
            - OS가 가상 메모리와 스압 파일에서 수행하는 방식과 유사 하지만 DB는 전체 메모리 페이지보다 개별 레코드 단위로 작업 가능하므로 더 효율적으로 메모리 관리 가능
    - 비휘발성 메모리
        - non-volatile memory
        - 새로운 연구 분야

- 트랜잭션 처리나 분석?
    - 트랜잭션    
        - 트랜잭션이란 용어는 논리 단위 형태로서 읽기와 쓰기 그룹을 나타내고 있다.
        - 트랜잭션이 반드시 ACID(원자성, 일관성 격리성, 지속성) 속성을 가질 필요는 없고, 지연시간이 낮은 읽기와 쓰기를 가능하게 하면 된다.
    - OLTP
        - 보통 app은 색인을 사용해 일부 키에 대한 적은 수의 레코드를 찾고, 레코드는 사용자 입력 기반으로 삽입되거나 갱신
        - 이런 app은 대화식이기 때문에 이 접근 패턴을 온라인 트랜잭션처리(online transaction processing OLTP) 라고 한다.
    - OLAP
        - DB를 데이터 분석에도 점점 사용하기 시작
        - 분석질의는 원시 데이터 반환이 아니라 많은 수의 레코드를 스캔해 레코드당 일부 칼럼만 읽어 집계 통계를 계산
        - 이런 질의는 회사 경영진이 더 나은 의사결정을 하게끔 돕는 보고서(BI)를 제공
        - 이런 패턴을 온라인 분석처리(online analytic processing OLAP)라고 부름
        - OLAP 유형 질의를 수행하기 위한 개별 DB를 데이터웨어하우스 라고 불렀다. 
    
    - 데이터 웨어하우징
        - OLTP 시스템은 사업 운영에 중요하기 때문에 높은 가용성과 낮은 지연시간의 트랜잭션 처리 기대
        - OLTP DB에 분석 질의 실행하는 것을 꺼려함
            - 이와 동시에 실행되는 트랜잭션의 성능 저하 가능성이 있어서
        - 데이터 웨어하우스는 분석가들이 OLTP 작업에 영향 주지 않고 마음껏 질의할 수 있는 개별 DB
        - DW는 OLTP 시스템에 있는 데이터의 읽기 전용 복사본이다.
        - 데이터 ETL
            - OLTP DB에서 추출(extract)
                - 주기적인 데이터 덤프나 지속적인 갱신 스트림을 사용해서
            - 분석 친화적인 스키마로 변환(transform)
            - 깨끗하게 정리한 다음 DW에 적재(load)
        - 개별 DW를 사용하는 가장 큰 장점은 분석 접근 패턴에 맞게 최적화 할 수 있다는 점. 
    
    
                    


